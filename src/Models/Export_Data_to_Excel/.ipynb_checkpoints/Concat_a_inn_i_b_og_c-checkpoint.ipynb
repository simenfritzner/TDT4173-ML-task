{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1697207503163,
     "user": {
      "displayName": "Simen Fritzner",
      "userId": "09016032329545939855"
     },
     "user_tz": -120
    },
    "id": "khXBbRzeGcwy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "#To update the imported files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utilities_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from constants import *\n",
    "from utilities import *\n",
    "sys.path.insert(0, '../RF')\n",
    "from utilities_RF import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 23:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32642</th>\n",
       "      <td>2023-04-22 10:00:00</td>\n",
       "      <td>320.909837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32686</th>\n",
       "      <td>2023-04-24 06:00:00</td>\n",
       "      <td>255.178152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32687</th>\n",
       "      <td>2023-04-24 07:00:00</td>\n",
       "      <td>449.964258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32688</th>\n",
       "      <td>2023-04-24 08:00:00</td>\n",
       "      <td>619.661318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32756</th>\n",
       "      <td>2023-04-27 04:00:00</td>\n",
       "      <td>28.412041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20643 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  pv_measurement\n",
       "0     2018-12-31 23:00:00        0.000000\n",
       "1     2019-01-01 00:00:00        0.000000\n",
       "2     2019-01-01 01:00:00        0.000000\n",
       "3     2019-01-01 02:00:00        0.000000\n",
       "4     2019-01-01 03:00:00        0.000000\n",
       "...                   ...             ...\n",
       "32642 2023-04-22 10:00:00      320.909837\n",
       "32686 2023-04-24 06:00:00      255.178152\n",
       "32687 2023-04-24 07:00:00      449.964258\n",
       "32688 2023-04-24 08:00:00      619.661318\n",
       "32756 2023-04-27 04:00:00       28.412041\n",
       "\n",
       "[20643 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_b_augmented = y_b\n",
    "y_c_augmented = y_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_a_to_the_other_datasets(X_train_a, y_a, X_train_other, y_other):\n",
    "    # Convert 'time' columns to datetime\n",
    "    y_a[\"new_time\"] = pd.to_datetime(y_a['time'])\n",
    "    y_other[\"new_time\"] = pd.to_datetime(y_other['time'])\n",
    "\n",
    "    # Extract month from datetime\n",
    "    y_a[\"month\"] = y_a['new_time'].dt.month\n",
    "    y_other[\"month\"] = y_other['new_time'].dt.month\n",
    "\n",
    "    # Iterate over each unique month\n",
    "    for month in y_a['month'].unique():\n",
    "        # Calculate average 'pv_measurement' for the current month in both datasets\n",
    "        average_pv_a = y_a.loc[y_a['month'] == month, 'pv_measurement'].mean()\n",
    "        average_pv_other = y_other.loc[y_other['month'] == month, 'pv_measurement'].mean()\n",
    "\n",
    "        # Calculate scaling factor\n",
    "        scaling_factor = average_pv_other / average_pv_a if average_pv_a != 0 else 0\n",
    "\n",
    "        # Apply scaling to 'pv_measurement' in y_a for the current month\n",
    "        y_a.loc[y_a['month'] == month, 'pv_measurement'] *= scaling_factor\n",
    "        \n",
    "    y_a.drop(columns=['new_time', 'month'], inplace=True)\n",
    "    y_other.drop(columns=['new_time', 'month'], inplace=True)\n",
    "    \n",
    "    X_train_other_and_a = pd.concat([X_train_a, X_train_other])\n",
    "    y_other_and_a = pd.concat([y_a, y_other])\n",
    "    \n",
    "    # Return the modified datasets\n",
    "    return X_train_other_and_a, y_other_and_a\n",
    "\n",
    "# Example usage\n",
    "# X_train_a, y_a, X_train_other, y_other = add_a_to_the_other_datasets(X_train_a, y_a, X_train_other, y_other)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gustav\\AppData\\Local\\Temp\\ipykernel_36168\\3962191667.py:27: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  X_train_other_and_a = pd.concat(X_train_a, X_train_other)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_other_and_a, y_other_and_a \u001b[38;5;241m=\u001b[39m add_a_to_the_other_datasets(X_observed_a, y_a, X_observed_b, y_b)\n",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m, in \u001b[0;36madd_a_to_the_other_datasets\u001b[1;34m(X_train_a, y_a, X_train_other, y_other)\u001b[0m\n\u001b[0;32m     24\u001b[0m y_a\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m y_other\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m X_train_other_and_a \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(X_train_a, X_train_other)\n\u001b[0;32m     28\u001b[0m y_other_and_a \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(y_other, y_a)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Return the modified datasets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:403\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    391\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m     sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    401\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(objs, (ABCSeries, ABCDataFrame, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    404\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument must be an iterable of pandas \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjects, you passed an object of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(objs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    406\u001b[0m         )\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m join \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintersect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "X_train_other_and_a, y_other_and_a = add_a_to_the_other_datasets(X_observed_a, y_a, X_observed_b, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNvDK8VkXGj55F7u4OPdtM3",
   "mount_file_id": "1V1XQmyvQ_eAqlX6BgUIYzGG-80Kblkug",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
